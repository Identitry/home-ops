---
# Namespace for Authentik
apiVersion: v1
kind: Namespace
metadata:
  name: authentik
  labels:
    app.kubernetes.io/name: authentik
    app.kubernetes.io/instance: authentik
    ingress.svc.egress: allow # <--- opt-in label for ingress-controller traffic
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd/helm-controller/main/config/crd/bases/helm.toolkit.fluxcd.io_helmrepositories.yaml
# Helm Repository for Authentik
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: authentik
  namespace: authentik
spec:
  interval: 1h
  url: https://charts.goauthentik.io
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/spotahome/redis-operator/refs/heads/master/manifests/databases.spotahome.com_redisfailovers.yaml
# RedisFailover for Authentik, used by Authentik for caching and task queues.
apiVersion: databases.spotahome.com/v1
kind: RedisFailover
metadata:
  name: authentik-redis
  namespace: authentik
spec:
  sentinel:
    replicas: 3
  redis:
    replicas: 3
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/external-secrets/external-secrets/refs/heads/main/config/crds/bases/external-secrets.io_externalsecrets.yaml
# App user credentials for the initial DB owner
apiVersion: external-secrets.io/v1
kind: ExternalSecret
metadata:
  name: es-authentik-db-creds
  namespace: authentik
spec:
  secretStoreRef:
    kind: ClusterSecretStore
    name: infisical
  target:
    name: authentik-db-creds
    creationPolicy: Owner
  data:
    - secretKey: username
      remoteRef:
        key: /AUTHENTIK/CNPG_USERNAME
    - secretKey: password
      remoteRef:
        key: /AUTHENTIK/CNPG_PASSWORD
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/external-secrets/external-secrets/refs/heads/main/config/crds/bases/external-secrets.io_externalsecrets.yaml
# Secret key for Authentik
apiVersion: external-secrets.io/v1
kind: ExternalSecret
metadata:
  name: es-authentik-config
  namespace: authentik
spec:
  secretStoreRef:
    kind: ClusterSecretStore
    name: infisical
  target:
    name: authentik-config
    creationPolicy: Owner
  data:
    - secretKey: secret_key
      remoteRef:
        key: /AUTHENTIK/SECRET_KEY
    - secretKey: email
      remoteRef:
        key: /AUTHENTIK/ADMIN_EMAIL
    - secretKey: password
      remoteRef:
        key: /AUTHENTIK/ADMIN_PASSWORD
    - secretKey: token
      remoteRef:
        key: /AUTHENTIK/ADMIN_TOKEN
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ak-blueprints
  namespace: authentik
data:
  ensure-defaults.yaml: |
    # yaml-language-server: $schema=https://goauthentik.io/blueprints/schema.json
    # NOTE:
    # We do NOT auto-meta-apply packaged defaults here to avoid race conditions.
    # Authentik loads its own defaults at startup. This blueprint only ensures
    # a Brand exists for your domain and leaves flows to the built-in defaults.
    version: 1
    metadata:
      name: Ensure brand for auth.${AK_DOMAIN}
      labels:
        blueprints.goauthentik.io/description: "Create/maintain Brand for auth.${AK_DOMAIN}"
        blueprints.goauthentik.io/instantiate: "false"  # prevent auto-run; apply via job
    context:
      domain_url: https://auth.${AK_DOMAIN}

    entries:
      - model: authentik_brands.brand
        state: present
        identifiers:
          domain: auth.${AK_DOMAIN}
        attrs:
          domain: auth.${AK_DOMAIN}
          default: false
          branding_title: "Authentik"

  00-core-prompts.yaml: |
    # yaml-language-server: $schema=https://goauthentik.io/blueprints/schema.json
    version: 1
    metadata:
      name: Ensure core prompt fields
      labels:
        blueprints.goauthentik.io/instantiate: "false"
    entries:
      # Password
      - model: authentik_stages_prompt.prompt
        state: present
        id: prompt-field-password
        identifiers:
          field_key: password
        attrs:
          label: "Password"
          type: password
          required: true
          placeholder: "Password"
          order: 30
          placeholder_expression: false

      # Password (repeat)
      - model: authentik_stages_prompt.prompt
        state: present
        id: prompt-field-password-repeat
        identifiers:
          field_key: password_repeat
        attrs:
          label: "Password (repeat)"
          type: password
          required: true
          placeholder: "Password (repeat)"
          order: 31
          placeholder_expression: false
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/config/crd/bases/postgresql.cnpg.io_clusters.yaml
# CloudNativePG Cluster â€” creates an "authentik" database owned by user "authentik"
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: authentik-db
  namespace: authentik
spec:
  instances: 2
  affinity:
    enablePodAntiAffinity: true
    topologyKey: kubernetes.io/hostname
    podAntiAffinityType: preferred

  storage:
    # Set your storageClass if needed (commented out to use cluster default)
    size: 5Gi

  bootstrap:
    initdb:
      database: authentik # database to create
      owner: authentik # owner of that database
      secret:
        name: authentik-db-creds # takes username/password from this Secret

  monitoring:
    enablePodMonitor: true
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd/helm-controller/main/config/crd/bases/helm.toolkit.fluxcd.io_helmreleases.yaml
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: authentik
  namespace: authentik
spec:
  chart:
    spec:
      chart: authentik
      version: 2025.8.4
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        namespace: authentik
        name: authentik
  interval: 1h
  driftDetection:
    mode: enabled
  values:
    global:
      priorityClassName: system-cluster-critical

      deploymentAnnotations:
        secret.reloader.stakater.com/reload: authentik-db-creds,authentik-config,wildcard-le-tls-cert

      env:
        - name: AUTHENTIK_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: authentik-config
              key: secret_key
        - name: AUTHENTIK_POSTGRESQL__HOST
          value: authentik-db-rw.authentik.svc
        - name: AUTHENTIK_POSTGRESQL__PASSWORD
          valueFrom:
            secretKeyRef:
              name: authentik-db-creds
              key: password
        - name: AUTHENTIK_POSTGRESQL__USER
          value: authentik
        - name: AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__HOST
          value: authentik-db-ro.authentik.svc
        - name: AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__NAME
          value: authentik
        - name: AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__USER
          value: authentik
        - name: AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__PASSWORD
          valueFrom:
            secretKeyRef:
              name: authentik-db-creds
              key: password
        - name: AUTHENTIK_REDIS__HOST
          value: rfrm-authentik-redis.authentik.svc
        - name: AUTHENTIK_DISABLE_UPDATE_CHECK
          value: "true"
        - name: AUTHENTIK_LOG_LEVEL
          value: warning
        - name: AUTHENTIK_HOST
          value: https://auth.${DOMAIN}
        - name: AUTHENTIK_COOKIE_DOMAIN
          value: .${DOMAIN}

    server:
      replicas: 1
      autoScaling:
        enabled: false

      ingress:
        enabled: true
        ingressClassName: tenant-root
        annotations:
          nginx.ingress.kubernetes.io/proxy-body-size: "16m"
          nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
          nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
          nginx.ingress.kubernetes.io/proxy-buffering: "off"
          nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
          external-dns.alpha.kubernetes.io/target: ${CLOUDFLARE_TUNNEL_TARGET}
          external-dns.alpha.kubernetes.io/cloudflare-proxied: "true"
          external-dns.alpha.kubernetes.io/hostname: "auth.${DOMAIN}"
          nginx.ingress.kubernetes.io/configuration-snippet: |
            proxy_set_header X-Forwarded-Proto https;
          nginx.ingress.kubernetes.io/backend-protocol: "HTTP"

        hosts:
          - auth.${DOMAIN}
        tls:
          - secretName: wildcard-le-tls-cert
            hosts:
              - auth.${DOMAIN}

      volumes:
        - name: media
          emptyDir: {}
        - name: postgres-creds
          secret:
            secretName: authentik-db-creds
        - name: user-blueprints
          configMap:
            name: ak-blueprints
      volumeMounts:
        - name: media
          mountPath: /media
        - name: postgres-creds
          mountPath: /postgres-creds
          readOnly: true
        - name: user-blueprints
          mountPath: /blueprints/user
          readOnly: true

    worker:
      replicas: 1
      autoScaling:
        enabled: false

      volumes:
        - name: media
          emptyDir: {}
        - name: postgres-creds
          secret:
            secretName: authentik-db-creds
        - name: user-blueprints
          configMap:
            name: ak-blueprints
      volumeMounts:
        - name: media
          mountPath: /media
        - name: postgres-creds
          mountPath: /postgres-creds
          readOnly: true
        - name: user-blueprints
          mountPath: /blueprints/user
          readOnly: true
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: authentik-blueprints-apply
  namespace: authentik
  labels:
    app.kubernetes.io/name: authentik
    app.kubernetes.io/instance: authentik
spec:
  schedule: "*/15 * * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 2
  jobTemplate:
    spec:
      backoffLimit: 2
      template:
        metadata:
          labels:
            app.kubernetes.io/name: authentik
            app.kubernetes.io/instance: authentik
        spec:
          restartPolicy: OnFailure
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          containers:
            - name: apply
              image: ghcr.io/goauthentik/server:2025.10.0
              imagePullPolicy: IfNotPresent
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
              terminationMessagePolicy: FallbackToLogsOnError
              env:
                - name: AUTHENTIK_SECRET_KEY
                  valueFrom:
                    secretKeyRef:
                      name: authentik-config
                      key: secret_key
                - name: AUTHENTIK_POSTGRESQL__HOST
                  value: authentik-db-rw.authentik.svc
                - name: AUTHENTIK_POSTGRESQL__USER
                  value: authentik
                - name: AUTHENTIK_POSTGRESQL__PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: authentik-db-creds
                      key: password
                - name: AUTHENTIK_REDIS__HOST
                  value: rfrm-authentik-redis.authentik.svc
                - name: AUTHENTIK_DISABLE_UPDATE_CHECK
                  value: "true"
                - name: AUTHENTIK_LOG_LEVEL
                  value: info
                - name: AUTHENTIK_HOST
                  value: https://auth.${DOMAIN}
                - name: AUTHENTIK_COOKIE_DOMAIN
                  value: .${DOMAIN}
                - name: AK_DOMAIN
                  value: ${DOMAIN}
              volumeMounts:
                - name: user-blueprints
                  mountPath: /blueprints/user
                  readOnly: true
                - name: blueprints-tmp
                  mountPath: /blueprints/tmp
              command:
                - sh
                - -lc
                - |
                  # BusyBox/Dash sh doesn't support 'pipefail'
                  set -eu
                  set -x
                  PY="$(command -v /ak-root/.venv/bin/python3 || command -v python3)"
                  # wait for Postgres & Redis to be reachable
                  "$PY" -c 'exec("import os, socket, time, sys\nimport socket as s\n\n\n\ndef wait(h,p,n, attempts=60, strict=True):\n    for _ in range(attempts):\n        sock=s.socket(); sock.settimeout(2)\n        try:\n            sock.connect((h,p)); sock.close(); return\n        except Exception:\n            time.sleep(2)\n    msg=f\"failed waiting for {n}\"\n    if strict:\n        print(msg, file=sys.stderr); sys.exit(1)\n    else:\n        print(\"WARN:\", msg, file=sys.stderr)\n\n# Strict wait for Postgres (required)\nwait(os.getenv(\"AUTHENTIK_POSTGRESQL__HOST\",\"authentik-db-rw.authentik.svc\"), 5432, \"postgres\", attempts=90, strict=True)\n# Best-effort wait for Redis (non-fatal)\nwait(os.getenv(\"AUTHENTIK_REDIS__HOST\",\"rfrm-authentik-redis.authentik.svc\"), 6379, \"redis\", attempts=30, strict=False)")'
                  # Apply ALL packaged defaults first (safe even if directory is empty)
                  for f in /blueprints/default/*.yaml; do
                    [ -f "$f" ] || continue
                    echo "[ak-blueprints] applying $f"
                    "$PY" /manage.py apply_blueprint "$f"
                  done
                  # Then apply user blueprints (idempotent) with runtime variable expansion
                  for f in /blueprints/user/*.yaml; do
                    [ -f "$f" ] || continue
                    mkdir -p /blueprints/tmp
                    tmpd="$(mktemp -d /blueprints/tmp/exp.XXXXXX)"
                    tmp="$tmpd/expanded.yaml"  # ensure .yaml suffix and under /blueprints/* so authentik accepts the path
                    F="$f" "$PY" -c 'import os,sys; p=os.environ["F"]; sys.stdout.write(os.path.expandvars(open(p, "r", encoding="utf-8").read()))' > "$tmp"
                    echo "[ak-blueprints] applying $tmp (source: $f)"
                    ls -l "$tmp"
                    "$PY" /manage.py apply_blueprint "$tmp"
                  done
                  echo "[ak-blueprints] all done"
          volumes:
            - name: user-blueprints
              configMap:
                name: ak-blueprints
            - name: blueprints-tmp
              emptyDir: {}
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/quick-install.yaml
apiVersion: cilium.io/v2
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: egress-authentik
spec:
  # Allow ingress-nginx pods (tenant-root) to reach Authentik server over service ports
  # Notes:
  # - Authentik Service exposes 80 (-> 9000) and 443 (-> 9443)
  # - We allow both 80/443 here; the target Pod listens on 9000/9443 behind the Service
  endpointSelector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
  egress:
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: authentik-server
      toPorts:
        - ports:
            - port: "80"
            - port: "443"
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/quick-install.yaml
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: authentik-egress
  namespace: authentik
spec:
  # Egress policy for Authentik server/worker pods
  # - Allow PostgreSQL (rw/ro) via Service IPs
  # - Allow Redis (master/replica) on 6379; remove Sentinel (not used)
  # - Allow DNS to CoreDNS; optional self-calls via Service on 80/443
  endpointSelector:
    # NOTE: This selector targets Authentik components only (server/worker); it does not apply to CNPG/Redis pods.
    matchLabels:
      app.kubernetes.io/name: authentik
  egress:
    # PostgreSQL RW Service
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: authentik-db-rw
      toPorts:
        - ports:
            - port: "5432"
    # PostgreSQL RO Service (used by read replicas)
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: authentik-db-ro
      toPorts:
        - ports:
            - port: "5432"
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: authentik-db-r
      toPorts:
        - ports:
            - port: "5432"
    # Redis master service (data port)
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: rfrm-authentik-redis
      toPorts:
        - ports:
            - port: "6379"

    # Redis replica service (some operator versions expose replicas via rfrs-<name>)
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: rfrs-authentik-redis
      toPorts:
        - ports:
            - port: "6379"

    # Fallback: allow to Redis pods by label (master/replicas)
    - toEndpoints:
        - matchLabels:
            io.kubernetes.pod.namespace: authentik
            app.kubernetes.io/name: authentik-redis
      toPorts:
        - ports:
            - port: "6379"
              protocol: TCP

    # DNS to CoreDNS service
    - toServices:
        - k8sService:
            namespace: kube-system
            serviceName: kube-dns
      toPorts:
        - ports:
            - port: "53"
              protocol: UDP
            - port: "53"
              protocol: TCP

    # Allow access to Kubernetes API (some components call /version). Needed for health/metadata checks.
    - toServices:
        - k8sService:
            namespace: default
            serviceName: kubernetes
      toPorts:
        - ports:
            - port: "443"

    # Extra safety: allow direct access to kube-apiserver entity (covers VIP changes/alt paths)
    - toEntities:
        - kube-apiserver
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP

    # Fallback for clusters where Service-based matching misses: allow the Service IP directly
    - toCIDR:
        - 10.96.0.1/32
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP

    # Allow node (host) IPs on 6443 for Kubernetes API (covers kube-proxy/OVN DNAT)
    - toEntities:
        - host
      toPorts:
        - ports:
            - port: "6443"
              protocol: TCP

    # Optional: allow Authentik to call its own Service (useful for callbacks/webhooks)
    - toServices:
        - k8sService:
            namespace: authentik
            serviceName: authentik-server
      toPorts:
        - ports:
            - port: "80"
            - port: "443"

    # Fallback: allow egress directly to CNPG Pods (when connecting by Pod IP)
    - toEndpoints:
        - matchLabels:
            io.kubernetes.pod.namespace: authentik
            cnpg.io/cluster: authentik-db
      toPorts:
        - ports:
            - port: "5432"
              protocol: TCP
